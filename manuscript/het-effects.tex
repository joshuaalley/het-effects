\documentclass[12pt]{article}
\usepackage{fullpage}
\usepackage{graphicx, rotating, booktabs} 
\usepackage{times} 
\usepackage{fbb} 
\usepackage{natbib} 
\usepackage{indentfirst} 
\usepackage{setspace}
\usepackage{grffile} 
\usepackage{hyperref}
\usepackage{tikz-cd}
 \usetikzlibrary{cd}
\usepackage[export]{adjustbox}
\usepackage[most]{tcolorbox}
\usepackage{verbatimbox}
\usepackage{lscape}
\usepackage{afterpage}
\usepackage{amsmath}
\usepackage[labelfont={bf},textfont=it,labelsep=period]{caption}
 \usepackage{multirow} 
\setcitestyle{aysep{}}
\usepackage{dcolumn}

\hypersetup{
  colorlinks = true,
  urlcolor = blue,
  linkcolor = black,
  citecolor = black,
  pdfauthor = {Joshua Alley},
  pdfkeywords = {},
  pdftitle = {},
  pdfsubject = {},
  pdfpagemode = UseNone,
%  pdffitwindow = true
%  pdfcenterwindow = true
}



\singlespace
\title{\textbf{Using Hierarchical Models to Estimate Heterogeneous Effects}}
\author{Joshua Alley \\
Assistant Professor \\
Baylor University \\
Joshua\_Alley@baylor.edu
}

 
\date{\today}

\bibliographystyle{apsr}

\usepackage{sectsty}
\sectionfont{\Large}
\subsectionfont{\noindent\large\textit}
\subsubsectionfont{\normalsize}

\makeatletter
\renewcommand\tiny{\@setfontsize\tiny{9}{10}}
\makeatother


\begin{document}

\maketitle 

\begin{abstract} 
%Heterogeneous effects are common in social science. 
This paper describes why, when, and how to use Bayesian hierarchical models to estimate heterogeneous effects. 
While an ample literature suggests that hierarchical models provide helpful regularization and information about effect variation, political scientists rarely use them to estimate heterogeneous effects. 
Doing so is simple, however, and starts with identify the key sources of heterogeneity. 
Then, researchers should fit a hierarchical model with two linked regressions, one connecting treatment with the outcome, and another that models the treatment effects with potential sources of heterogeneity and partially pools group estimates.
This captures systematic and random variation in heterogeneous effects, encompasses the diversity of interactions in theories, and fits commonly used modeling frameworks. 
Hierarchical modeling is more flexible than linear interactions and reduces the risk of underpowered subgroup comparisons.
It also provides a more interpretable framework for testing theories than machine-learning tools. 
The downside is that this approach employs very strong regularization, which breaks down if there are many small groups.
I document these claims with a simulation analysis and extension of a published study. 
%Researchers can thus use hierarchical models alongside other approaches to understand heterogeneous effects for scholarship and policy.
\end{abstract} 


\newpage 
\doublespace 


%\section{Introduction}


% one: het effects matter
Whether in observational or experimental studies, every independent variable social scientists examine impacts some units differently than others. 
Common estimands aggregate heterogeneous effects.\footnote{For instance, \citet{Abramsonetal2022} note that the average marginal component effect (AMCE) of conjoint experiments gives more weight to intense preferences.} 
Such average effects are useful, but they often obscure interesting and important variation. 


Understanding heterogeneous effects is essential for policy and scholarship. 
Estimating heterogeneity allows scholars to clarify when an independent variable most or least impacts some outcome.
Policymakers can maximize the impact of finite resources with targeted interventions, for example by providing job training to individuals who are more likely to benefit. 
% expand/sharpen this, if there is space. (There is not for PA) 

% two: introduce my solution 
This paper explains why, when and how to use hierarchical models to estimate heterogeneous effects. 
A large statistics literature suggests that Bayesian hierarchical models are a useful tool for  heterogeneous effects estimation (e.g., \cite{FellerGelman2015, McElreath2016, Dorieetal2022}).
Political scientists tend to rely on interactions or machine learning tools instead, however.  
For instance, of the three applied political science citations of \citet{FellerGelman2015}, only \citet{Marquardt2022} models treatment effects. 


% power problems
This oversight matters because there are few tools that are well-suited to test the proliferation of conditional arguments in the social science. 
Social scientists often propose conditional theories \citep{ClarkGolder2023} and are interested in how different people respond to the same stimulus for normative or policy reasons.
Many theories proposing distinct modifiers for the same independent variable and interest in diverse subgroups suggest that multiple modifiers are the rule, not the exception.  
For example, international relations scholarship on audience costs has considered how foreign policy dispositions \citep{KertzerBrutger2016}, partisanship \citep{LevenduskyHorowitz2012}, gender \citep{Barnhartetal2020, SchwartzBlair2020} and policy preferences \citep{Chaudoin2014} modify individual reactions to a leader backing down from a threat.


Such proliferation of theoretically informed modifiers complicates empirical testing. 
Scholars cannot ignore heterogeneity, but the most common tools either increase the risk of spurious results or are hard to interpret and use. 
Interaction terms and subgroup analysis are the most common tool. 
Simple interactions and subgroup analyses are ubiquitous because they are relatively easy to interpret, but they have serious power concerns. 
Many political science analyses have low power even to detect main effects \citep{ArelBundocketal2025}.
Adequate power for estimates of even a single interaction can require significantly more data \citep{Gelman2018}, which may be prohibitively expensive or impossible.
As a result, statistically significant heterogeneous effect estimates may be far too large--- the result of noise in the data, not systematic differences. 
This problem is partially responsible for widespread issues replicating findings based on interactions \citep{Simmonsetal2011}. 


Even when theory implies many potential modifiers, modeling such theories with interactions is not easy. 
The interpretation benefits of interactions diminish as researchers add more variables.
Adding variables to an interaction further raises the risk of spurious inferences due to power concerns and picking up noise in ever smaller subgroups.


% three: loads of techniques
Given multiple sources of heterogeneity, machine-learning tools such as random forests \citep{GreenKern2012, WagerAthey2018}, support vector machines \citep{ImaiRatkovic2013}, and ensemble methods \citep{Grimmeretal2017, Kuenzeletal2019, Dorieetal2022} are more likely to avoid over-fitting.
These machine learning algorithms usually have some regularization component and can discover complex patterns and high-dimensional variation across multiple modifiers.\footnote{\citet{BlackwellOlson2022} describe a lasso approach to interactions that sits between machine learning and linear regressions.}
These tools can be difficult to interpret and implement, however, especially in smaller social science datasets. 
The relative lack of theoretical guidance and interpretability is especially problematic for testing multiple conditional arguments.


The hierarchical strategy I propose here addresses the power shortcomings of interactions while retaining more theoretical structure than machine learning.
I do this by showing how scholars can use two connected regressions to estimate theoretically informed models of heterogeneous effects.
Using hierarchical models is more flexible than standard interactions but easier to implement and interpret than machine learning.  
It preserves a straightforward structure while accommodating more factors and ameliorating the downsides of subgroup analysis. 
This facilitates argument testing.
The main downside is that unlike machine learning, the hierarchical approach lacks the flexibility to discover high-dimensional heterogeneity and regularization will break down if there are many small groups.
It also may not scale to very large datasets, depending on the underlying sampler.
Hierarchical modeling therefore works best when theory indicates more than two modifying factors and there is less emphasis on discovery.\footnote{\citet{Goplerud2021} introduces a model that uses Bayesian structured sparsity to estimate which group coefficients are similar and which are different. In this approach, researchers use theory to inform potential groups, but the data determines common estimates for groups.} 


%Hierarchical modeling has an additional benefit of bridging the disparate estimates of interactions and machine learning. 
%Many interactions functionally estimate grouped effects--- individuals with the same values of the modifiers will have the same effect estimate. 
%Machine learning models usually estimate individual effects. 
%The model I propose here gives individual estimates with the systematic group component and a way to account for and regularize individual deviations from those groups.


There are two key steps when theory and data make using hierarchical models worthwhile.
First, researchers should identify potential modifiers of a treatment and use them to model treatment effects.
Second, they should take that model of treatment effects and connect it to a model linking individual treatment effects and the outcome.
Modeling heterogeneous effects in this way produces interpretable results, which facilitates argument testing.
It also allows researchers to compare different sources of heterogeneous effects and describe how much an effect varies.  
These are crucial advantages in a world with many conditional theories.


While frequentist estimation of hierarchical models is possible, Bayesian estimation is easy, usually fast, and more informative.
Bayesian estimation provides crucial information by connecting parameters through common prior distributions, thereby regularizing estimates and propagating uncertainty. 
Working with posterior distributions also gives researchers more flexibility to describe how and when effects vary. 
While computation and coding were once a barrier to employing Bayesian methods, fitting a wide range of hierarchical models is straightforward with the brms package in \textsf{R} \citep{Buerkner2017}.\footnote{I provide example code below and in the appendix.}
%Calculating substantive effects is also simple \citep{ArelBundockme}.



% wrap and introduce the application 
In the remainder of this paper, I describe how and when to estimate hierarchical models of heterogeneous effects.
I then employ a simulation study to compare OLS and hierarchical estimates of individual treatment effects under different conditions.
Finally, I demonstrate the process by analyzing a study of how military alliances shape public support for war by \citet{TomzWeeks2021}. 
The reanalysis reveals that alliances exert the strongest impact on respondents with high internationalism and interest in the news. 
It also documents the importance of regularization in analyzing subgroups derived from combinations of experimental treatments.
%Alliances increase mass support for war by impacting individuals who otherwise prefer peaceful collaboration. 



\section{Hierarchical Modeling of Heterogeneous Effects}


There are two steps in hierarchical models of heterogeneous effects. 
First, researchers must identify potential sources of heterogeneity, and think about the right model of heterogeneity.
This will also depend on what variation is most important and interesting. 
Theory, policy concerns, or normative factors are all possible motivations. 


This first step determines what heterogeneous effects a researcher estimates. 
It is analogous to researchers thinking through a regression specification and requires the same sort of care. 
Researchers need to define what variation is most important, link heterogeneous effects to theory, and structure modeling.
This is especially important for pre-registration, and could reduce the amount of exploratory analyses in registrations.
Not thinking carefully about sources of heterogeneity will obfuscate results and can hinder model fitting.
   

% three ways to set groups
There are three general approaches to defining key modifiers.  
First, researchers can use combinations of other treatments, especially when an intervention has several dimensions but theory emphasizes one of them. 
The experimental design determines modifiers, and the model estimates heterogeneous treatment effects.   
If researchers want to know how different issues shape the impact of elite foreign policy cues \citep{GuisingerSaunders2017}, they could include indicators of issues, for instance.
A similar application of hierarchical estimators for topic-sampling experiments estimates how a treatment effect varies across topics \citep{CliffordRainey2023}. 


The most common practice in estimating heterogeneous treatment effects is fully crossed interactions.
This estimates the impact of a treatment across experimental strata, but risks spurious results by functionally estimating subgroup results.
Most social science papers do not have adequate power for main effects \citep{ArelBundocketal2025}, however, let alone small subgroups that many times have 50 or fewer data points.


A second approach uses unit, demographic and contextual factors to estimate effect heterogeneity. 
Here, researchers examine what factors within or around units shape their response to an independent variable.
Researchers could use a mix of individual and contextual factors to predict divergent consequences of a survey experiment treatment. 
Such a model might include factors such as an indicator of state of residence, age, gender, and race.\footnote{Extrapolations to a representative sample of a subpopulation might require poststratification.}


For example, \citet{Alley2021isq} uses alliance characteristics to examine when alliance membership increases or decreases military spending.
He models the impact of alliance participation as a function of treaty depth, partner democracy, conditions on military support, issue linkages, democratic membership, foreign policy concessions and other factors. 
All of these variables are potential sources of credibility or confounding factors.
Democratic alliances have higher depth \citep{Martin2005}, so this model of heterogeneity accounts for potential confounding, and finds that after accounting for depth, democracy does not impact the relationship between alliances and defense spending, contrary to \citet{DiGiuseppePoast2018}.


Third, researchers might use hierarchical models to address specific policy concerns.
Policy analysts often want to know how an intervention impacts a specific population. 
Researchers might want to know if a job-training program improves employment outcomes for black women in the South, for instance.  
To do this, a researcher might specify a heterogeneous effects model with race, gender and region, plus additional controls or other factors.

%CUT CANDIDATE
%Interacting modifiers can be a useful component of this hierarchical approach.

% grouping factors: numbers 
%Whether researchers use other treatments, context, or policy to determine what drives heterogeneity, group composition should depend first on the research question.
%There are some practical constraints, however.
%Using too many factors can lead to model fitting and interpretation problems by creating many small groups.
%How many factors is too many depends especially on the data- some datasets can support reasonably large groups for many factors. 
%At the other extreme, using only one grouping factor in a hierarchical model will usually add relatively little value compared to interactions. 


After defining moderators and how they relate to individual effects, the second step is fitting a hierarchical model that links a model of the outcome with a model of heterogeneity.
Essentially, researchers model the outcome and the process that produces heterogeneous treatments. 
The model employs two connected regressions.
One regression deals with the outcome, and includes the treatment effects.\footnote{If other units such as states define the groups, rather than combinations of modifying variables, then adding group-level predictors to this equation is essential. For examine, in a model where an effect varies by state, adding state-level variables like ideology, population and GDP would avoid partially pooling small groups too far towards the overall mean.}


The other regression models the treatment effects.
In this regression, theory should inform which modifiers predict the treatment effect. 
To regularize the estimates, this second equation must include varying intercepts for groups within the data. 
Groups can be based on combinations of discrete modifiers and binned continuous modifiers. 
To maximize variation and preserve regularization, researchers should use continuous modifiers directly in the regression and bin them for setting groups. 
Not binning modifiers will create many small groups, leading the hierarchical component to lose value.
As a result, this model includes both systematic and random variation in the impact of a key independent variable on different groups.


Setting groups is a critical task that requires balancing detail against the value of regularization.
Larger groups can deviate more from the overall mean, as their data contributes more the posterior than the prior.
A few small groups means less need for a hierarchical model.
Smaller groups will be shrunk more towards the overall mean.
Too many small groups and the regularization component will have less information to work with. 


I now briefly describe a generic hierarchical model. 
For ease of exposition, consider making between-unit comparisons based on an experimental treatment.    
Start with \textit{N} units indexed by \textit{i}, some of which receive a binary treatment \textit{T}.
Assume that the outcome variable ${y}$ is normally distributed with mean $\mu_i$ and standard deviation $\sigma$.\footnote{Researchers can and should use binary, categorical and other outcome likelihoods.}
\textit{g} indexes researcher-defined groups based on combinations of the modifying variables.


%The first equation predicts the outcome mean. 
The outcome for each unit depends on an overall intercept, an optional matrix of control variables \textbf{X}, and a set of group treatment effects $\lambda_g$.
When \textit{T} is binary, estimated $\lambda$ parameters for untreated units have no impact on the outcome and drop out of the likelihood.
For a continuous treatment, the impact of of treatment will depend on the product of $\textit{T}_i$ and $\lambda$.



\begin{align*}
y_i &\sim N(\mu_i, \sigma) &\text{(Likelihood)} \\
\mu_i &= \alpha + \lambda_g \textit{T} + \textbf{X} \beta &\text{(Outcome Equation)}  \\ 
\lambda_g &= \theta_g + \textbf{Z} \gamma  &\text{(Heterogeneity Equation)}\\
\theta_g &\sim N(\mu_\theta, \sigma_\theta) &\text{(Indiviudal Varying Intercepts)} 
%\gamma &\sim N(0, 1) &\text{Problem-Specific Prior} \\ 
%\beta &\sim N(0, 1) &\text{Problem-Specific Prior} \\ 
%\alpha &\sim N(0, 1) &\text{Problem-Specific Prior} \\ 
\end{align*}



%The outcome for each unit is then a function of group varying intercepts $\alpha_g$, an optional matrix of control variables \textbf{X}, and a set of group treatment effects $\theta_g$.
%The researcher divides all units into \textit{g} groups based on unique combinations of heterogeneous effect predictors \textbf{Z}. 
%Each $\theta$ parameter estimates how the treatment effect varies across the values of  each variable.  
%To capture correlations between the random intercepts and varying slopes $\rho \sigma_\alpha \sigma_\theta$, these variables should have a common multivariate normal prior.

%\begin{align*}
%y_i &\sim N(\mu_i, \sigma) &\text{(Likelihood)} \\
%\mu_i &= \alpha + \alpha_{g1} + \theta_{g1} \textit{T} + \alpha_{g2} + \theta_{g2} \textit{T} + \textbf{X} \beta &\text{(Outcome Equation)}  \\ 
%\begin{pmatrix} 
%\alpha_{g} \\
%\theta_{g} \\
%\end{pmatrix} &\sim  N
%\begin{bmatrix}
%\begin{pmatrix}
%\mu^\alpha_{g} \\
%\mu^\theta_{g} \\
%\end{pmatrix}\!\!,&
%\begin{pmatrix}
%\sigma^2_\alpha & \rho \sigma^\alpha_{g} \sigma^\theta_{g} \\
%\rho \sigma^\alpha_{g} \sigma^\theta_{g} & \sigma^2_\theta \\
%\end{pmatrix}
%\end{bmatrix} & \text{(Common Prior)} \\ 
%%\begin{pmatrix} 
%%\alpha_{g1} \\
%%\theta_{g1} \\
%%\end{pmatrix} &\sim  N
%%\begin{bmatrix}
%%\begin{pmatrix}
%%\mu^\alpha_{g2} \\
%%\mu^\theta_{g2} \\
%%\end{pmatrix}\!\!,&
%%\begin{pmatrix}
%%\sigma^2_\alpha & \rho \sigma^\alpha_{g2} \sigma^\theta_{g2} \\
%%\rho \sigma^\alpha_{g2} \sigma^\theta_{g2} & \sigma^2_\theta \\
%%\end{pmatrix}
%%\end{bmatrix} & \text{(Common Prior: G2)} \\ 
%%\begin{pmatrix} 
%%\alpha_{g1*g2} \\
%%\theta_{g1*g2} \\
%%\end{pmatrix} &\sim  N
%%\begin{bmatrix}
%%\begin{pmatrix}
%%\mu^\alpha_{g1*g2} \\
%%\mu^\theta_{g1*g2} \\
%%\end{pmatrix}\!\!,&
%%\begin{pmatrix}
%%\sigma^2_\alpha & \rho \sigma^\alpha_{g1*g2} \sigma^\theta_{g1*g2} \\
%%\rho \sigma^\alpha_{g1*g2} \sigma^\theta_{g1*g2} & \sigma^2_\theta \\
%%\end{pmatrix}
%%\end{bmatrix} & \text{(Common Prior: g1*g1)} \\ 
%%\theta_g &= \theta_{g1} \textit{G1} + \theta_{g2} \textit{G2} & \text{(Group Slopes)} \\
%%\alpha_g &= \alpha_{g1} + \alpha_{g2} & \text{(Group Intercepts)} \\
%%\mu_\theta &= \lambda_0 + \textbf{Z} \lambda &\text{(Heterogeneous Effects)} 
%\end{align*}
%
%This approach lets slopes vary across groups. 
%This is a relatively simple model.\footnote{In brms for a model with no controls and two groups modifying the impact of a treatment, the model formula is y $\sim$ 1 + (1 + treat | group1 + group2)}  
%Researchers could modify this to fit panel data, account for autocorrelation, or make any other necessary adjustments.
%
%
%The slopes and intercepts can also be nested via interactions of grouping variables. 
%In that instance, the net impact of the treatment in each group depends on the linear combination of slopes in that group, specifically the $\theta$ parameters at the specific values of each variable. 
%Similarly, the group intercepts would be the sum of the corresponding random intercepts for each grouping variable.

%The heterogeneous effects equation then predicts the treatment effects with the matrix \textbf{Z}, which contains unique combinations of whatever variables define the groups.  
%As a result, each $\theta$ reflects a unique mix of factors that modify the treatment.
%The second equation also includes an intercept $\lambda_0$ that estimates the impact of treatment when all sources of heterogeneity are zero.\footnote{In brms for a model with no controls and two variables modifying the impact of a treatment, the model formula is y $\sim$ 1 + treat*(var1 + var2) + (1 + treat | var1:var2). treat*(var1 + var2) expresses part of the second equation, while (1 + treat | var1:var2) lets slopes vary by group.}

The heterogeneity equation then models those individual treatment effects with a systematic and random component. 
The systematic component is a matrix of predictors \textbf{Z} and associated parameters $\gamma$. 
$Z$ can mirror any regression specification researchers might use for an outcome; linear combinations of variables, interactions, smooth functions. 
Interactions of the modifiers could capture processes where combinations of modifiers produce non-additive jumps in heterogeneity, for instance.


The random component of the heterogeneity equation is a series of individual-specific varying intercepts $\theta_i$.
These are critical, because they capture group deviations from the systematic trends expressed in the design matrix \textbf{Z}. 
Group outliers in the $\lambda$ estimates are partially pooled back towards the overall mean $\mu_\theta$.
The variance parameter $\sigma_\theta$ controls the dispersion of the group effects around the overall mean.\footnote{In brms, using non-linear syntax can express a model with a treatment, two controls, and three modifiers as: y $\sim$ lambda * treat + controls, lambda $\sim$ mod1 + mod2 + mod3 + (1 | mod1 + mod2 + mod3), controls $\sim$ coutrol1 + control2, nl = TRUE}


The above model can be fit with Bayesian or frequentist methods, but Bayesian estimation offers important advantages.
First, it is more flexible, and including prior information can facilitate model fitting and convergence. 
Putting priors on the $\alpha$, $\beta$, and $\gamma$ parameters is especially helpful.
Priors also help regularize estimates by pulling extreme groups towards the overall mean.
Working with posterior distributions also also provides a wealth of information about effect heterogeneity and propagates uncertainty.  
Last, Bayesian models can provide useful diagnostics such as divergent transitions that can be warnings of specification problems.
A model that is hard to fit oftentimes should be modified, not brute-forced through the sampler. 


% Interpretation 
In interpreting these estimates, researchers should leverage the full range of information from the different parameters. 
First, the $\lambda$ posteriors give the impact of the treatment on each individual, and are the core quantity of interest. 
All $\lambda$s reflect a systematic component from the predictors in $\textbf{Z}\gamma$ and a random variations from $\theta$. 
$\gamma$ parameters can, depending on the regression, be interpreted as the impact of a change in a modifier on the treatment effects.
For example, a $\gamma$ of .1 on a binary modifier means that $\lambda$ is .1 higher in expectation when the modifier is one, and .1 lower when it is zero.
$\sigma_\theta$ thus measures the extent of individual variation that is outside the systematic regression. 
Other techniques such as interactions in OLS with robust standard errors provide less information.


\section{When to Use Hierarchical Models}

% advantages 
In deciding whether to use a hierarchical model, researchers must weigh specific advantages and disadvantages. 
In general, estimating heterogeneous effects in this way has three advantages.
First, researchers can make detailed inferences about heterogeneous effects in an interpretable framework that encompasses many potential modifiers.
This helps examine theories that predict how an effect varies and compare sources of variation.\footnote{Rescaling variables in the heterogeneous effects equation can aid model fitting and coefficient comparisons \citep{Gelman2008}.} 
Partial pooling also facilitates reasonable estimates for small groups by sharing information across groups and incorporating predictors in the heterogeneous effects equation. 
Finally, this approach will be faster than machine learning approaches for many datasets as well as easier to use in small datasets.


% disadvantages
Like all methods, the hierarchical approach has downsides, some of which can be ameliorated with modifications, while others should lead researchers to use different tools. 
Extremely complex specifications can lead to model fitting problems.
Sometimes, fitting problems indicate that the model is misspecified, so these problems are themselves informative. 
Hard to fit models may need to be simplified, especially if there are many small groups.
Again, many small groups will also reduce the regularization benefits of the hierarchical model, as there is less information to estimate $\sigma_\theta$.  


Furthermore, hierarchical models can show general trends, but will not make powerful comparisons between every group treatment effect. 
Researchers who want to compare specific effects will often lack empirical leverage.
This downside can also apply to other methods, however. 


% Relative to interactions
With these considerations in mind, when should researchers use hierarchical models in place of interactions?
If only one factor modifies an effect, interactions are best, as the extra information hierarchical models provide is less valuable. 
Researchers should still remember power concerns with interactions, however. 


% two modifiers
With two or more modifiers, hierarchical models begin to add value. 
Interpreting triple interactions between a variable and two modifiers is challenging. 
The advantages of hierarchical modeling increase with the number of modifiers until too many modifiers create many small groups.


% not as well suited for discovery 
The relative use cases of hierarchical models and machine learning are different. 
Unlike machine learning approaches, hierarchical models will not discover high-dimensional interactions. 
Researchers can add flexibility with additional interactions or non-linear specifications in either level of the model, but this requires a priori specification. 
Therefore, if researchers want to focus on flexible discovery, not testing an argument with multiple sources of treatment heterogeneity, machine-learning is a better tool. 


Data size is relevant to model selection as well. 
All of these models benefit from more data, as machine-learning models can draw out patterns and interactions have greater power. 
Hierarchical models also benefit from more data, but are less sensitive to outliers in small samples. 
The challenge is that some hierarchical models can take a long time to fit on large datasets. 
Variational approximation can ameliorate this problem, but these methods require careful validation.


\begin{table}[htbp]
\centering
\caption{Key characteristics of different approaches to estimating heterogeneous effects.}
\label{tab:tools-det}
\begin{tabular}{@{}lp{1.3in}p{1.5in}p{1.3in}@{}}
\toprule
\textbf{Characteristic} & \textbf{Hierarchical Models} & \textbf{Interactions} & \textbf{Machine Learning} \\
\midrule
Factors              & Two or more          & One or two         & Many \\ 
\addlinespace
Ideal Sample Size    & Medium               & Medium to large   & Large \\ 
\addlinespace
Complexity           & Medium               & Low                & High \\ 
\addlinespace
Computational Cost   & Model dependent      & Low                & Variable \\ 
\addlinespace
Interpretability     & High                 & High               & Low \\ 
\addlinespace
Modifiers            & Specified            & Specified          & Discovered/specified \\
\bottomrule
\end{tabular}
\end{table}


In summary, researchers should continue to use interactions for single modifiers and machine learning to discover complex interactions. 
Hierarchical modeling works well when there are two or more modifiers and researchers have adequate data to support an informative model.  
Hierarchical modeling is especially important when there are multiple modifiers from different theories of treatment heterogeneity or heterogeneous effects.



\autoref{tab:tools-det} summarizes some relevant characteristics of hierarchical, interaction and machine learning approaches to heterogeneous effects. 
Interactions work well with a few modifiers, a medium to large sample, and are easy to integrate with theory. 
Machine-learning tools are best for discovery with many modifiers in large datasets, but can be harder to tie into existing arguments. 
Hierarchical models are marginally more difficult to use than interactions, but researchers gain an interpretable way to tackle multiple modifiers in a theoretically-driven model.
I now document gains of hierarchical models compared to interactions with simulated data.
I do not include machine-learning tools in the simulation because they often produce different effects, such as individual-level estimates that are not directly comparable to the group-level hierarchical and interaction estimates.




\section{Performance on Simulated Data}

To assess how this hierarchical model compares to interactions, I first assess their performance on simulated data. 
Each simulation approximates the two most common applications of these models. 
The first simulates estimating treatment heterogeneity in factorial experiments that have an even number of data points in each group.
The second simulation deals with imbalanced groups, as would likely be the case in demographic analyses of heterogeneous effects. 
In both simulations, I attempt to push the limits of group construction to illustrate when hierarchical modeling becomes more or less accurate.


Both simulations fix the number of observations at 2,000 and manipulate the number of groups.
In each simulation, the data generating process includes group-specific effects, drawn from a normal distribution with a mean of .2 and variance of .3.
I also add three control variables with fixed coefficients the predict the mean of the simulated outcome.
The simulated outcome has a standard deviation of one.


To compare the models, I use the root-mean squared error of the coefficient estimates compared to the true value. 
I use root mean squared error because the hierarchical model's reduction of variance may introduce bias \citep{CliffordRainey2024}.
Lower variance may overcome greater bias in some coefficients and make the hierarchical model more accurate on average.


In the first simulation, I divide the 2,000 observations into equally sized combinations of three to seven binary variables, each with equal probability. 
This creates 8 to 128 unique groups, with 250 observations per group at the low end and 16 observations at the high end.
I then fit OLS models with fully crossed interactions of the group variables, as these estimate treatment effects in each subgroup.
Fully crossed interactions are also a standard tool for estimating effects in each combination of experimental treatments.
In the hierarchical model, I use fully crossed interactions of the group variables in the heterogeneity equation and set a random intercept for each group.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/sim-spec-rmse.png}
	\caption{Comparison of OLS and hierarchical root mean squared error in group coefficient estimates. Simulation fixes the sample size at 2,000 observations and varies the number of groups. Each group has the same number of observations.}
	\label{fig:sim-spec-rmse}
\end{figure}


\autoref{fig:sim-spec-rmse} presents the results of this first simulation.
When the groups are large because there are thee grouping variables, there is a small gap in model performance. 
The hierarchical model is marginally more accurate, however.
But as group numbers rise and the number of observations in each group falls, root mean squared error rises for all models, but the OLS with fully crossed interactions performs much worse. 
With 128 groups and 16 observations per group, the OLS model has a root mean squared error of .5, while the hierarchical model is at .33.  


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/sim-spec-scatter.png}
	\caption{Comparison of OLS and hierarchical estimates of group-specific treatment effects. Points on the dashed line are unbiased.}
	\label{fig:sim-spec-scatter}
\end{figure}


These benefits are due to strongly reduced variance in the hierarchical estimates, as \autoref{fig:sim-spec-scatter} shows. 
This figure plots the true group treatment effects against the model estimates.
Points above the dotted line are over-estimated by the model compared to the true value, while points below are under-estimated.


Even with 8 groups and 250 observations per group, more OLS estimates are unbiased, but two groups are clearly off. 
This means that even with slight bias for all groups, the hierarchical estimates have lower overall root mean squared error.
As the number of groups increases and group size falls, the estimates for both models become more noisy, but the hierarchical model estimates are far less variable. 
Lower variance makes the hierarchical model much more accurate on average.


This is essential because the dramatic over and under-estimates in the OLS model are the subgroup estimates with the greatest likelihood of statistical significance. 
But most of these estimates are very biased and reflect noise in the data, not a true effect. 
The problems this poses for replication are now well understood, and the hierarchical model offers a clear solution.


The second simulation shows similar improvements with unbalanced group sizes.
The relative benefits of hierarchical modeling fall as the number of small groups in the data rises, however.
Here, I set the number of groups to 64, using six binary grouping variables. 
I then vary the probability of each group level and the symmetry of these probabilities across groups.
Balanced groups are equivalent to the 64 group case in the first simulation. 
At the strongest imbalance, one group has a 20\% share of ones and 80\% zeros, and another has the opposite extreme, with a range in between.
Such extreme imbalance can leave as few as one observation in each group, so it is an extreme test of model performance. 
Again, I compare the models with the root mean squared error of the coefficient estimates, and show these results in \autoref{fig:sim-groupsize-rmse}.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/sim-groupsize-rmse.png}
	\caption{Comparison of OLS and hierarchical root mean squared error in group coefficient estimates. Simulation fixes the sample size at 2,000 observations and varies the relative size of different groups.}
	\label{fig:sim-groupsize-rmse}
\end{figure}


Under balanced groups, the hierarchical model has a significant advantage. 
The smaller and more numerous the groups, the less valuable hierarchical regularization becomes, however. 
Small groups add far less information and are strongly pulled to the overall mean, which itself is a function of the larger groups.
Again, the strong imbalance creates conditions where it is wiser to set up less finely-tuned groups or expand the sample size so groups have more observations and information to contribute to partial pooling.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/sim-groupsize-bias.png}
	\caption{Comparison of OLS and hierarchical model bias in estimates of group-specific treatment effects. Group size gives the number of observations in each group, and bias is expressed as an absolute value. Loess lines give average bias across the range of observations.}
	\label{fig:sim-groupsize-bias}
\end{figure}


To further illustrate how group size shapes the hierarchical estimates, I plot the bias of the OLS and hierarchical models in \autoref{fig:sim-groupsize-bias}.
Again, the OLS estimator has significant bias for some groups as the model picks up noise.
The magnitude of the bias does not depend on group size. 
In fact, large groups often have more bias because the OLS estimates weight each group equally. 


The hierarchical model has much less bias for larger groups. 
Smaller groups with less than 20 data points have higher bias, while large groups, especially those with 75 or more observations, have more data and less bias.
This is partial pooling in action.
Small groups do not have much information, so the prior informs those estimates more than the limited data. 
Large groups have enough data to deviate from the prior and hit the true value.


The simulations thus give two crucial inferences.
First, partial pooling and modeling treatment effects offers significant improvements in inference, as it reduces variance in the estimates. 
The relative size of groups shapes the magnitude of this benefit, as hierarchical models will be less biased for large groups and more biased with small groups under extreme imbalances in group size. 
This means that the smaller the group, the less a hierarchical model can tell you, but the estimate will often be more accurate than interactions regardless. 
Individual estimates may not be perfectly unbiased and comparing groups will be difficult.


\section{Example Application: Alliances and Public Support for War} 


In the following, I demonstrate how the hierarchical approach works in practice and compares to prior applied work reanalyzing a study by \citet{TomzWeeks2021}. 
Tomz and Weeks (TW hereafter) examine whether the public is more willing to go to war for when the beneficiary of that intervention is a U.S. ally.
In a factorial experiment with vignettes, they find a 33\% average increase in support for military intervention on behalf of allies, compared to non-allies. 
This is a large and potentially important relationship because the United States has a global network of allies. 


Given the size of the main effect, TW's paper is an ideal scenario for comparing interactions and hierarchical models. 
Corresponding interaction effects may be large, and their sample size of 1,200 respondents is not unusual in published work. 
At the same time, TW estimated many interactions to check how other treatments modify the impact of alliances.
There are 64 unique treatment groups with anywhere from 11 to 32 respondents, so estimates of the impact of alliances in the 32 pairs of alliance treatment and control groups employ at most 54 data points. 
As such, hierarchical regularization will likely change some conclusions by pooling noisy estimates in small groups.
I document these gains by analyzing how other experimental treatments modify the impact of alliances, and then exploring how demographic differences modify the alliance treatment. 



\subsection{Differences by Experimental Scenario}


Along with alliances, TW randomly assign whether the potential beneficiary of U.S. intervention is a democracy or not, the stakes of intervention, the potential costs, and the region of the world. 
They estimate the impact of alliances in the 32 treatment conditions with an OLS model that fully crosses interactions between the treatments, and calculate marginal effects over different averages of these groups. 
I use a hierarchical model to estimate the impact of alliances, with fully crossed experimental treatments as the systematic modifiers of the alliance effect and group-specific intercepts.
This mirrors TW's model, but regularizes the estimates with partial pooling.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/tw-het-treat-comp.png}
	\caption{Comparison of OLS and hierarchical estimates of the impact of alliance across experimental conditions. The top panel gives a histogram of the treatment effects from each model. The bottom panel gives the difference between the hierarchical and OLS estimates for each group.}
	\label{fig:tw-het-treat-comp}
\end{figure}


\autoref{fig:tw-het-treat-comp} compares the estimated alliance treatment effects across the experimental groups with the OLS and hierarchical models.
This figure illustrates the regularization of hierarchical modeling in two ways.
It shows the difference between the median hierarchical estimate and the OLS estimate for each combination of treatment groups and plots the distribution of effects.


First, the hierarchical estimates are much less variable and more tightly clustered around the overall mean.
This occurs because the OLS model mechanically forces individual treatment effect estimates to the value of the coefficients and corresponding subgroup means. 
Given the size of this sample, the treatment effects are based on comparisons of roughly 25 treatment and 25 control respondents. 


Second, the hierarchical estimates pull in unusual values.
The bottom panel of \autoref{fig:tw-het-treat-comp} shows the difference between the hierarchical and the OLS estimate for each group.
The downward slope from positive to negative values means that the hierarchical estimates are larger than below average OLS estimates, but smaller than above average interaction estimates. 
This occurs because hierarchical estimates are pulled towards the overall mean, away from extreme values.
The OLS model finds one scenario where alliances reduce support by almost 20\%, but the hierarchical model treats this as noise and brings it towards the grand mean.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/tw-het-treat-source.png}
	\caption{Comparison of OLS and hierarchical estimates of the impact of alliance across experimental conditions. Each point gives the effect estimate for each group.}
	\label{fig:tw-het-treat-source}
\end{figure}


I compare the estimates for each group with greater detail about what shapes each heterogeneous treatment in \autoref{fig:tw-het-treat-source}.
This clearly shows the reduced variation in the hierarchical estimates across the different experimental conditions.
In some cases, the hierarchical and OLS estimates are very similar, but the model suggests that in a smaller sample, saturated interactions of treatment effects overstate effect heterogeneity. 
For some conditions, such as a low-stakes, low-cost intervention to support a South American autocracy, the hierarchical estimate is 30\% lower than the OLS estimate. 
The condition where TW find a 20\% drop in support for an ally compared to a non-ally is a high-cost intervention on behalf of an Eastern European democracy. 
That would be concerning, but the hierarchical model suggests that this is closer to 30\%, which matches findings on how randomly assigning NATO membership to different Eastern European states impacts U.S. public support for war \citep{Tomz2023}.


Given the very large average effect of alliances, these results do not change the direction of the findings- in some scenarios they even strengthen them. 
However, the magnitudes of some subgroup estimates do matter, as they might lead observers to misidentify when alliances matter most.
The hierarchical models suggest that low stakes are not as influential as the OLS results indicate, for example.
For other, smaller effects, regularization with a hierarchical model might change inferences in subgroup analysis. 


\subsection{Who Responds to Alliances}


To further explore the potential application of hierarchical models, this section examines how demographic factors modify the impact of alliances.
I used party, political interest, race, and gender to modify the impact of alliances.
I selected these variables because Tomz and Weeks examine party and political interest as potential modifiers, but gender \citep{Barnhartetal2020} and race are also salient modifiers.
I control for other experimental manipulations, age and education.
Age and education are important group-level controls because they are group-level variables that are correlated across party, race and gender.
Following TW's OLS analysis, I use a Gaussian likelihood, although the outcome is a binary variable. 


The resulting hierarchical model thus encompasses four subgroup comparisons in TW's appendix while adding two more modifiers.
All of the comparisons encapsulated in the hierarchical model would require at least six pairwise interaction models. 
What TW present in four figures, I am able to do in two while adding more information.



To start, I plot the two regressions of hierarchical model. 
\autoref{fig:tw-het-source} plots how different variables shape either the impact of an alliance or support for intervention. 
One facet of this figure gives the coefficient estimates from the model of heterogeneity, and a second gives the control estimates. 



\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/tw-treat-het-source.png}
	\caption{Variation in the impact of alliances on support for military intervention across four variables that set groups. Each point marks the impact of alliances on a specific group, and boxplots summarize the median and interquartile range of the slopes within each level of the variable. All slopes are present in each facet.}
	\label{fig:tw-het-source}
\end{figure}


High news interest is the strongest predictor of how alliances impact support for war. 
Respondents with high news interest respond to alliances by .15 more than others in this survey, and that relationship could be as small as .05 or as large as .22.
This differs from TW's conclusion that respondents with high and low news interest respond in roughly the same way, likely because the hierarchical model accounts for other factors that are correlated with news interest.


Other demographic predictors do not differentiate responses to alliances as clearly. 
The impact of alliances may be somewhat greater for white and male respondents, but those differences are not clearly different from zero as the 95\% credible intervals include zero and small negative values.
Similarly, Republicans and Democrats are not all that different from independents in how they respond to alliances.
This matches TW's conclusion that partisanship does not create substantial differences in alliance effects.
The intercept in this equation is theoretically meaningful, as it captures the impact of alliances when all the modifiers are zero. 
For independent, non-white women with low news interest, alliances increase support for force by roughly .15. 


The control equation suggests that high stakes, high costs, and partner democracy all increase support for intervention.
Region is less consequential, as neither Asia, Eastern Europe nor Africa is clearly different from the reference category of Latin America.
Because neither education nor age are equal to zero, the intercept is not directly interpretable.


\begin{figure}[htpb]
	\centering
		\includegraphics[width=0.95\textwidth]{../figures/tw-treat-het-joint.png}
	\caption{Estimated impact of alliance on support for military intervention in different subgroups of respondents. Text gives the exact posterior median estimate.}
	\label{fig:tw-treat-het-joint}
\end{figure}



While it is possible to construct a rough profile of who responds most to alliances using the estimates in \autoref{fig:tw-het-source}, I provide a more precise summary in \autoref{fig:tw-treat-het-joint}. 
This figure plots the median estimate in each group of respondents, after grouping respondents based on race, gender, news interest and partisanship.
There are 24 unique estimates, all of which are clearly greater than zero. 
Alliances thus increase support for using force among all demographic groups, but the magnitude of the effect varies. 


Alliances most impact white Republican men with high interest in the news. 
In this group, the impact of alliances is .5, because this group was skeptical of intervention without an alliance rationale. 
The gap between high and low news interest in the other demographic groups is .15, which matches the coefficient in the heterogeneity equation.


The weakest impact of alliances appears for non-white, politically independent women with low news interest.
Here, alliances increase support for force by 13\%. 
White respondents respond by 8\% more, Democrats by 4\% more, and Republicans by 10\%. 
The accumulation of these different effects create substantial gaps between the groups.


% variation
These results show some potential uses of the hierarchical approach to heterogeneous effects.\footnote{In the appendix, I analyze \citet{BushPrather2020}.}
Regularization moderates what might otherwise be extreme inferences about experimental subgroups.
It also provides useful inferences about treatment heterogeneity that account for overlap among different sources of heterogeneity.



\section{Conclusion}


This paper details why, when and how to use hierarchical models to estimate heterogeneous effects. 
Bayesian modeling can apply to a wide range of outcomes, data structures, and theories. 
It also details what drives variation in an effect and how much an effect varies. 
Explicitly modeling how different groups respond to an independent variable can help test arguments and inform policy.  


Hierarchical modeling provides an intermediate approach between interactions or subgroup analyses and machine learning algorithms. 
For interactions with one or perhaps two modifiers, relying on simple interaction tools is best. 
Machine learning is best for discovery of complex heterogeneity.
When there are two or more theoretically informed modifiers, hierarchical modeling allows flexible and interpretable estimation of effect variation. 


As a result, hierarchical modeling complements existing tools and should not replace them. 
Researchers can use hierarchical models to check and inform other techniques, for instance by seeing if a key interaction holds when there are multiple modifiers, or comparing multiple modifiers that past theories have identified. 
Using hierarchical modeling can thus help scholars and policymakers better understand heterogeneous effects.


\section*{Acknowledgements}

Thanks to Taylor Kinsley Chewning, Andrew Gelman, Carlisle Rainey and Rod Sturdivant for helpful comments.

\singlespace
\bibliography{../../MasterBibliography} 


%\input{../appendix/appendix.tex}

\end{document}

